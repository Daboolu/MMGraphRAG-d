"""
å¤šæ¨¡æ€çŸ¥è¯†å›¾è°±æ£€ç´¢æ¨¡å— (RAG)

ç»“åˆäº†è½»é‡çº§æ£€ç´¢ (Cosine Similarity) å’Œå¤šæ¨¡æ€ç”Ÿæˆ (LLM/MLLM) èƒ½åŠ›ã€‚
"""
import asyncio
import base64
import json
import logging
import os
import re
from dataclasses import dataclass, field
from pathlib import Path
from typing import List, Dict, Tuple, Any

import networkx as nx
import numpy as np
from sklearn.metrics.pairwise import cosine_similarity

from ..core.base import (
    logger,
    load_json,
    write_json,
    split_string_by_multi_markers,
    truncate_list_by_token_size,
    list_of_list_to_csv,
    check_json_not_empty
)
from ..parameter import (
    QueryParam,
    OUTPUT_DIR,
    WORKING_DIR,
    RETRIEVAL_THRESHOLD,
    EMBED_MODEL,
    MMKG_NAME
)
from ..llm import model_if_cache, multimodel_if_cache
from ..core.prompt import PROMPTS, GRAPH_FIELD_SEP


# ==================== å…¨å±€ç¼“å­˜ ====================
_graph_cache = {}      # {graphml_path: nx.Graph}
_embedding_cache = {}  # {graphml_path: embeddings_dict}


# ==================== åŸºç¡€æ£€ç´¢åŠŸèƒ½ ====================

def read_graphml(graphml_file: str) -> nx.Graph:
    """è¯»å–GraphMLæ–‡ä»¶ï¼ˆå¸¦ç¼“å­˜ï¼‰"""
    if graphml_file in _graph_cache:
        return _graph_cache[graphml_file]
    
    if not os.path.exists(graphml_file):
        logger.warning(f"æœªæ‰¾åˆ°GraphMLæ–‡ä»¶: {graphml_file}")
        return nx.Graph()

    graph = nx.read_graphml(graphml_file)
    _graph_cache[graphml_file] = graph
    return graph

def build_node_embeddings(graph: nx.Graph) -> Dict[str, np.ndarray]:
    """æ„å»ºèŠ‚ç‚¹çš„embedding"""
    embeddings = {}
    # å‡è®¾ EMBED_MODEL å·²ç»åˆå§‹åŒ–
    if EMBED_MODEL is None:
        logger.error("â— Embeddingæ¨¡å‹æœªåˆå§‹åŒ–ï¼")
        return {}

    for node, data in graph.nodes(data=True):
        description = data.get('description', '')
        # å¦‚æœæ²¡æœ‰æè¿°ï¼Œä½¿ç”¨èŠ‚ç‚¹ID
        text = description if description else node
        embedding = EMBED_MODEL.encode(text, show_progress_bar=False)
        embeddings[node] = embedding
    return embeddings

def get_embedding_path(graphml_path: str) -> str:
    """æ ¹æ®graphmlæ–‡ä»¶è·¯å¾„ç¡®å®šembeddingæ–‡ä»¶è·¯å¾„"""
    path = Path(graphml_path)
    return str(path.parent / f"{path.stem}_emb.npy")

def load_or_build_embeddings(graph: nx.Graph, graphml_path: str) -> Dict[str, np.ndarray]:
    """åŠ è½½æˆ–æ„å»ºèŠ‚ç‚¹embeddings"""
    if graphml_path in _embedding_cache:
        return _embedding_cache[graphml_path]
    
    emb_path = get_embedding_path(graphml_path)
    
    if os.path.exists(emb_path):
        logger.info(f"ğŸ“‚ åŠ è½½embedding: {os.path.basename(emb_path)}")
        embeddings = np.load(emb_path, allow_pickle=True).item()
    else:
        logger.info(f"ğŸ”¨ æ„å»ºembedding: {os.path.basename(emb_path)}")
        embeddings = build_node_embeddings(graph)
        np.save(emb_path, embeddings)
        logger.info("âœ… Embeddingå·²ä¿å­˜")
    
    _embedding_cache[graphml_path] = embeddings
    return embeddings

def find_similar_nodes(prompt: str, embeddings: Dict[str, np.ndarray], 
                      threshold: float, top_k: int) -> List[Dict]:
    """æŸ¥æ‰¾ä¸promptç›¸ä¼¼çš„èŠ‚ç‚¹ï¼Œè¿”å› [{entity_name, score, rank}]"""
    if not embeddings:
        return []
        
    prompt_embedding = EMBED_MODEL.encode(prompt, show_progress_bar=False)
    
    results = []
    for node, emb in embeddings.items():
        sim = cosine_similarity([prompt_embedding], [emb])[0][0]
        if sim >= threshold:
            results.append({"entity_name": node, "score": float(sim)})
            
    # æ’åºå¹¶å–Top K
    results.sort(key=lambda x: x["score"], reverse=True)
    results = results[:top_k]
    
    # æ·»åŠ rank
    for i, res in enumerate(results):
        res["rank"] = i
        
    return results


# ==================== ä¸Šä¸‹æ–‡æ„å»ºé€»è¾‘ ====================

def img_path2chunk_id(data: dict, img_data: dict) -> dict:
    """å»ºç«‹ image_path åˆ° chunk_id çš„æ˜ å°„å¹¶æ›¿æ¢"""
    path_to_chunk = {v["image_path"]: v["chunk_id"] for v in img_data.values()}

    for key, value_set in data.items():
        updated_values = set()
        for value in value_set:
            if isinstance(value, str) and value.endswith('.jpg'):
                chunk_id = path_to_chunk.get(value)
                if chunk_id:
                    updated_values.add(chunk_id)
            else:
                updated_values.add(value)
        data[key] = updated_values
    return data

async def _find_most_related_text_unit_from_entities(
    node_datas: list[dict],
    query_param: QueryParam,
    text_chunks: dict, # å†…å­˜ä¸­çš„dict
    graph: nx.Graph,   # nx.Graphå¯¹è±¡
):
    """ä»å®ä½“ä¸­æŸ¥æ‰¾ç›¸å…³æ–‡æœ¬å•å…ƒ"""
    # 1. è·å– Source ID
    text_units = [
        split_string_by_multi_markers(dp.get("source_id", ""), [GRAPH_FIELD_SEP])
        for dp in node_datas
    ]
    
    # 2. è·å–ä¸€è·³é‚»å±…
    all_one_hop_nodes = set()
    edges_list = [] # å­˜å‚¨æ¯ä¸ªèŠ‚ç‚¹çš„è¾¹
    
    for dp in node_datas:
        node = dp["entity_name"]
        if graph.has_node(node):
            curr_edges = list(graph.edges(node))
            edges_list.append(curr_edges)
            for u, v in curr_edges:
                neighbor = v if u == node else u
                all_one_hop_nodes.add(neighbor)
        else:
            edges_list.append([])

    # 3. è·å–ä¸€è·³é‚»å±…æ•°æ®
    all_one_hop_nodes = list(all_one_hop_nodes)
    all_one_hop_nodes_data = [
        graph.nodes[n] if graph.has_node(n) else {} 
        for n in all_one_hop_nodes
    ]
    
    # 4. æ„å»ºä¸€è·³èŠ‚ç‚¹çš„æ–‡æœ¬å•å…ƒæ˜ å°„
    all_one_hop_text_units_lookup = {
        n: set(split_string_by_multi_markers(d.get("source_id", ""), [GRAPH_FIELD_SEP]))
        for n, d in zip(all_one_hop_nodes, all_one_hop_nodes_data)
        if "source_id" in d
    }
    
    # 5. æ ¹æ®å›¾åƒæ•°æ®è¿›è¡Œæ­£åˆ™åŒ– (éœ€è¦åŠ è½½ image_data)
    img_data_path = os.path.join(WORKING_DIR, 'kv_store_image_data.json')
    if os.path.exists(img_data_path):
        image_data = load_json(img_data_path)
        if image_data:
            all_one_hop_text_units_lookup = img_path2chunk_id(all_one_hop_text_units_lookup, image_data)
            
    # 6. è®¡ç®—ç›¸å…³åº¦
    all_text_units_lookup = {}
    
    for index, (this_text_units, this_edges) in enumerate(zip(text_units, edges_list)):
        for c_id in this_text_units:
            if not c_id.startswith('chunk-'):
                continue
            if c_id in all_text_units_lookup:
                continue
                
            relation_counts = 0
            for u, v in this_edges:
                neighbor = v if u == node_datas[index]["entity_name"] else u
                if neighbor in all_one_hop_text_units_lookup:
                    if c_id in all_one_hop_text_units_lookup[neighbor]:
                        relation_counts += 1
            
            chunk_data = text_chunks.get(c_id)
            if chunk_data:
                all_text_units_lookup[c_id] = {
                    "data": chunk_data,
                    "order": index,
                    "relation_counts": relation_counts
                }

    # 7. æ’åºå¹¶æˆªæ–­
    all_text_units = [
        {"id": k, **v} for k, v in all_text_units_lookup.items()
    ]
    all_text_units.sort(key=lambda x: (x["order"], -x["relation_counts"]))
    
    all_text_units = truncate_list_by_token_size(
        all_text_units,
        key=lambda x: x["data"].get("content", ""),
        max_token_size=query_param.local_max_token_for_text_unit
    )
    
    return [t["data"] for t in all_text_units]

def _find_most_related_edges_from_entities(
    node_datas: list[dict],
    query_param: QueryParam,
    graph: nx.Graph
):
    """æŸ¥æ‰¾æœ€ç›¸å…³çš„è¾¹"""
    all_related_edges_set = set()
    
    for dp in node_datas:
        node = dp["entity_name"]
        if graph.has_node(node):
            for u, v in graph.edges(node):
                # æ’åºå…ƒç»„ä»¥å»é‡æ— å‘è¾¹
                edge_key = tuple(sorted((u, v)))
                all_related_edges_set.add(edge_key)
                
    all_edges = list(all_related_edges_set)
    all_edges_data = []
    
    for u, v in all_edges:
        if graph.has_edge(u, v):
            data = graph.get_edge_data(u, v)
            # è®¡ç®—edge degree (ç®€å•èµ·è§ï¼Œè¿™é‡Œç”¨ä¸¤ç«¯èŠ‚ç‚¹çš„åº¦æ•°ä¹‹å’Œ)
            degree = graph.degree(u) + graph.degree(v)
            all_edges_data.append({
                "src_tgt": (u, v),
                "rank": degree,
                "description": data.get("description", ""),
                "weight": data.get("weight", 1.0)
            })
            
    # æ’åºå’Œæˆªæ–­
    all_edges_data.sort(key=lambda x: (x["rank"], x["weight"]), reverse=True)
    
    all_edges_data = truncate_list_by_token_size(
        all_edges_data,
        key=lambda x: x["description"],
        max_token_size=query_param.local_max_token_for_local_context
    )
    
    return all_edges_data

async def _build_local_query_context(
    query: str,
    graph: nx.Graph,
    embeddings: Dict[str, np.ndarray],
    text_chunks: dict,
    query_param: QueryParam
) -> Tuple[str, str]:
    """æ„å»ºæœ¬åœ°æŸ¥è¯¢ä¸Šä¸‹æ–‡"""
    # 1. æŸ¥æ‰¾ç›¸ä¼¼èŠ‚ç‚¹
    results = find_similar_nodes(query, embeddings, RETRIEVAL_THRESHOLD, query_param.top_k)
    
    if not results:
        return "", None
        
    # 2. è¡¥å…¨èŠ‚ç‚¹æ•°æ®
    node_datas = []
    for r in results:
        node_name = r["entity_name"]
        if graph.has_node(node_name):
            data = graph.nodes[node_name]
            node_datas.append({
                "entity_name": node_name,
                "entity_type": data.get("entity_type", "UNKNOWN"),
                "description": data.get("description", "UNKNOWN"),
                "rank": graph.degree(node_name), # ä½¿ç”¨åº¦æ•°ä½œä¸ºrank
                "source_id": data.get("source_id", "")
            })

    # 3. è·å–ç›¸å…³æ–‡æœ¬å’Œå…³ç³»
    use_text_units = await _find_most_related_text_unit_from_entities(
        node_datas, query_param, text_chunks, graph
    )
    
    use_relations = _find_most_related_edges_from_entities(
        node_datas, query_param, graph
    )
    
    logger.info(
        f"ä¸Šä¸‹æ–‡: {len(node_datas)} ä¸ªå®ä½“, {len(use_relations)} æ¡å…³ç³», {len(use_text_units)} ä¸ªæ–‡æœ¬å•å…ƒ"
    )

    # 4. æ„å»º CSV ä¸Šä¸‹æ–‡
    # Entities Section
    entities_list = [["id", "entity", "type", "description", "rank"]]
    for i, n in enumerate(node_datas):
        entities_list.append([
            i, n["entity_name"], n["entity_type"], n["description"], n["rank"]
        ])
    entities_context = list_of_list_to_csv(entities_list)
    
    # Relations Section
    relations_list = [["id", "source", "target", "description", "weight", "rank"]]
    for i, e in enumerate(use_relations):
        relations_list.append([
            i, e["src_tgt"][0], e["src_tgt"][1], e["description"], e["weight"], e["rank"]
        ])
    relations_context = list_of_list_to_csv(relations_list)
    
    # Text Units Section
    text_units_list = [["id", "content"]]
    for i, t in enumerate(use_text_units):
        text_units_list.append([i, t.get("content", "")])
    text_units_context = list_of_list_to_csv(text_units_list)
    
    # 5. ç»„åˆæœ€ç»ˆä¸Šä¸‹æ–‡
    context = f"""
    -----Entities-----
    ```csv
    {entities_context}
    ```
    -----Relationships-----
    ```csv
    {relations_context}
    ```
    -----Sources-----
    ```csv
    {text_units_context}
    ```
    """
    return entities_context, context


# ==================== GraphRAGQuery ç±» ====================

@dataclass
class GraphRAGQuery:
    working_dir: str = WORKING_DIR
    output_dir: str = OUTPUT_DIR
    graph: nx.Graph = field(init=False)
    embeddings: Dict = field(init=False)
    text_chunks: Dict = field(init=False)
    image_data: Dict = field(init=False)
    
    def __post_init__(self):
        # 1. åŠ è½½å›¾è°± (ä¼˜å…ˆåŠ è½½é…ç½®çš„ MMKG_NAME)
        graph_path = None
        
        # ä¼˜å…ˆçº§ 1: paramter.py ä¸­å®šä¹‰çš„ MMKG_NAME
        if MMKG_NAME:
            candidate = os.path.join(self.output_dir, f"{MMKG_NAME}.graphml")
            if os.path.exists(candidate):
                graph_path = candidate
                
        # ä¼˜å…ˆçº§ 2: è‡ªåŠ¨æŸ¥æ‰¾ output_dir ä¸‹æœ€æ–°çš„ .graphml æ–‡ä»¶
        if not graph_path and os.path.exists(self.output_dir):
            graph_files = [
                os.path.join(self.output_dir, f) 
                for f in os.listdir(self.output_dir) 
                if f.endswith('.graphml')
            ]
            if graph_files:
                # æŒ‰ä¿®æ”¹æ—¶é—´å€’åºæ’åºï¼Œå–æœ€æ–°çš„
                graph_files.sort(key=lambda x: os.path.getmtime(x), reverse=True)
                graph_path = graph_files[0]
                logger.info(f"è‡ªåŠ¨å®šä½åˆ°æœ€æ–°çš„çŸ¥è¯†å›¾è°±æ–‡ä»¶: {os.path.basename(graph_path)}")
        
        self.graph = read_graphml(graph_path)
        logger.info(f"ä» {graph_path} åŠ è½½å›¾è°±: {self.graph.number_of_nodes()} ä¸ªèŠ‚ç‚¹")
        
        # 2. åŠ è½½ Embeddings
        self.embeddings = load_or_build_embeddings(self.graph, graph_path)
        
        # 3. åŠ è½½ Text Chunks
        chunks_path = os.path.join(self.working_dir, "kv_store_text_chunks.json")
        self.text_chunks = load_json(chunks_path) or {}
        
        # 4. åŠ è½½ Image Data
        img_data_path = os.path.join(self.working_dir, "kv_store_image_data.json")
        self.image_data = load_json(img_data_path) or {}

    async def query(self, query: str, param: QueryParam = QueryParam()) -> str:
        """æ‰§è¡Œ RAG æŸ¥è¯¢"""
        log_entries = [] # ç”¨äºMarkdownæ—¥å¿—
        log_entries.append(f"## Query: {query}")
        
        # 1. æ„å»ºä¸Šä¸‹æ–‡
        entities_context, context = await _build_local_query_context(
            query, self.graph, self.embeddings, self.text_chunks, param
        )
        
        if context is None:
            log_entries.append("**Result**: Failed to build context (no relevant entities found).")
            self._save_log_to_markdown("\n\n".join(log_entries))
            return PROMPTS["fail_response"]
            
        log_entries.append("### Context")
        log_entries.append(context)

        # 2. LLM åˆå§‹å›ç­”
        sys_prompt = PROMPTS["local_rag_response_augmented"].format(
            context_data=context, 
            response_type=param.response_type
        )
        response_text = await model_if_cache(query, system_prompt=sys_prompt)
        
        log_entries.append("### Initial LLM Response")
        log_entries.append(response_text)

        # 3. å¤šæ¨¡æ€å¢å¼º
        # è§£æ entities_context æŸ¥æ‰¾å›¾ç‰‡å®ä½“ (ORI_IMG)
        img_entities = []
        if entities_context:
            for line in entities_context.split("\n")[1:]:
                parts = line.split(",")
                if len(parts) >= 3 and "ORI_IMG" in parts[2]:
                    entity_name = parts[1].strip().strip('"')
                    img_entities.append(entity_name)
                    
        img_entities = list(set([e.lower() for e in img_entities]))[:param.number_of_mmentities]
        
        if not img_entities:
            self._save_log_to_markdown("\n\n".join(log_entries))
            return response_text
            
        logger.info(f"ä½¿ç”¨å¤šæ¨¡æ€å®ä½“: {img_entities}")
        log_entries.append(f"### Multimodal Processing ({len(img_entities)} images)")
        
        mm_responses = []
        for entity in img_entities:
            if entity not in self.image_data:
                continue
                
            img_info = self.image_data[entity]
            img_path = img_info["image_path"]
            
            # Path check fix
            if not os.path.exists(img_path):
                # Try to fix path relative to working dir
                fname = os.path.basename(img_path)
                img_path = os.path.join(self.working_dir, "images", fname)
                
            if not os.path.exists(img_path):
                logger.warning(f"æœªæ‰¾åˆ°å›¾ç‰‡: {img_path}")
                continue
                
            try:
                with open(img_path, "rb") as f:
                    img_base64 = base64.b64encode(f.read()).decode("utf-8")
                
                info_text = f"{img_info.get('caption','')}, {img_info.get('footnote','')}"
                mm_prompt = PROMPTS["local_rag_response_multimodal"].format(
                    context_data=context,
                    response_type=param.response_type,
                    image_information=info_text
                )
                
                mm_res = await multimodel_if_cache(
                    f"Query: {query}",
                    img_base=img_base64,
                    system_prompt=mm_prompt
                )
                mm_responses.append(mm_res)
                log_entries.append(f"**Image**: {img_path}\n**Response**: {mm_res}")
                
            except Exception as e:
                logger.error(f"å¤„ç†å›¾ç‰‡å‡ºé”™ {img_path}: {e}")

        if not mm_responses:
            self._save_log_to_markdown("\n\n".join(log_entries))
            return response_text

        # 4. èåˆå›ç­”
        merge_prompt = PROMPTS["local_rag_response_multimodal_merge"].format(
            mm_responses=json.dumps(mm_responses, ensure_ascii=False)
        )
        mm_merged_response = await model_if_cache(query, system_prompt=merge_prompt)
        
        log_entries.append("### Merged Multimodal Response")
        log_entries.append(mm_merged_response)

        # 5. æœ€ç»ˆç”Ÿæˆ
        final_prompt = PROMPTS["local_rag_response_merge"].format(
            response_type=param.response_type,
            mm_response=mm_merged_response,
            response=response_text
        )
        final_response = await model_if_cache(f"Query: {query}", system_prompt=final_prompt)
        
        log_entries.append("### Final Response")
        log_entries.append(final_response)
        
        self._save_log_to_markdown("\n\n".join(log_entries))
        return final_response

    def _save_log_to_markdown(self, content: str):
        """ä¿å­˜æ—¥å¿—åˆ°Markdownæ–‡ä»¶"""
        if not os.path.exists(self.output_dir):
            os.makedirs(self.output_dir, exist_ok=True)
            
        log_path = os.path.join(self.output_dir, "retrieval_log.md")
        with open(log_path, "a", encoding="utf-8") as f:
            f.write(f"\n\n---\n\n{content}")
