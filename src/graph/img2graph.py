"""
å›¾åƒçŸ¥è¯†å›¾è°±æ„å»ºæ¨¡å—

ä»å›¾åƒä¸­æå–å®ä½“å’Œå…³ç³»ï¼Œæ„å»ºçŸ¥è¯†å›¾è°±ã€‚

ä¸»è¦åŠŸèƒ½:
1. å›¾åƒåˆ†å‰² (YOLO) - æå–å›¾åƒç‰¹å¾å—
2. ç‰¹å¾å—å®ä½“æå– - ä¸ºæ¯ä¸ªç‰¹å¾å—ç”Ÿæˆæè¿°
3. å®ä½“å…³ç³»æ„å»º - å»ºç«‹å®ä½“ä¹‹é—´çš„å…³ç³»
"""
import asyncio
import base64
import os
import shutil
import re
from functools import partial
from pathlib import Path
from typing import cast, Type, Union
from dataclasses import dataclass
from collections import defaultdict

import cv2
import numpy as np
from PIL import Image
from tqdm import tqdm
from ultralytics import YOLO

from ..core.base import load_json, limit_async_func_call, logger, split_string_by_multi_markers
from .utils import (
    _handle_single_entity_extraction,
    _handle_single_relationship_extraction,
    _merge_nodes_then_upsert,
    _merge_edges_then_upsert,
)
from ..llm import multimodel_if_cache
from ..core.prompt import PROMPTS
from ..core.storage import BaseGraphStorage, BaseKVStorage, JsonKVStorage, NetworkXStorage, StorageNameSpace
from .. import parameter


# ============================================================================
# å¸¸é‡
# ============================================================================

TUPLE_DELIMITER = PROMPTS["DEFAULT_TUPLE_DELIMITER"]
RECORD_DELIMITER = PROMPTS["DEFAULT_RECORD_DELIMITER"]
COMPLETION_DELIMITER = PROMPTS["DEFAULT_COMPLETION_DELIMITER"]
MIN_IMAGE_SIZE = 28  # æœ€å°å›¾åƒå°ºå¯¸


# ============================================================================
# å›¾åƒåˆ†å‰²
# ============================================================================

async def extract_feature_chunks(image_path: str) -> str:
    """
    ä½¿ç”¨YOLOå¯¹å›¾åƒè¿›è¡Œåˆ†å‰²ï¼Œæå–ç‰¹å¾å—ã€‚
    
    Returns:
        ç‰¹å¾å—ä¿å­˜ç›®å½•è·¯å¾„
    """
    image_name = Path(image_path).stem
    save_dir = os.path.join(parameter.WORKING_DIR, "images", image_name)
    os.makedirs(save_dir, exist_ok=True)
    
    # æ£€æŸ¥æ˜¯å¦éœ€è¦åˆ†å‰²
    image_data = load_json(os.path.join(parameter.WORKING_DIR, "kv_store_image_data.json")) or {}
    should_segment = any(
        v.get("image_path") == image_path and v.get("segmentation", False)
        for v in image_data.values()
    )
    
    if not should_segment:
        return save_dir
    
    # YOLOåˆ†å‰²
    yolo_path = os.path.join(os.path.dirname(__file__), "yolov8n-seg.pt")
    model = YOLO(yolo_path)
    results = model(image_path, device='cpu')
    
    for result in results:
        img = np.copy(result.orig_img)
        img_name = Path(result.path).stem
        
        for idx, detection in enumerate(result):
            label = detection.names[detection.boxes.cls.tolist().pop()]
            
            # åˆ›å»ºæ©è†œ
            mask = np.zeros(img.shape[:2], np.uint8)
            contour = detection.masks.xy.pop().astype(np.int32).reshape(-1, 1, 2)
            cv2.drawContours(mask, [contour], -1, (255, 255, 255), cv2.FILLED)
            
            # åº”ç”¨æ©è†œ
            mask_3ch = cv2.cvtColor(mask, cv2.COLOR_GRAY2BGR)
            isolated = cv2.bitwise_and(mask_3ch, img)
            
            # è£å‰ªåˆ°è¾¹ç•Œæ¡†
            x1, y1, x2, y2 = detection.boxes.xyxy[0].cpu().numpy().astype(np.int32)
            cropped = isolated[y1:y2, x1:x2]
            
            # ä¿å­˜
            save_path = os.path.join(save_dir, f"{img_name}_{label}-{idx}.jpg")
            cv2.imwrite(save_path, cropped)
    
    return save_dir


# ============================================================================
# å®ä½“æå–è¾…åŠ©å‡½æ•°
# ============================================================================

def _encode_image_base64(image_path: str) -> str:
    """å°†å›¾åƒç¼–ç ä¸ºBase64"""
    with open(image_path, "rb") as f:
        return base64.b64encode(f.read()).decode("utf-8")


def _get_jpg_files(directory: str) -> list[str]:
    """è·å–ç›®å½•ä¸‹æ‰€æœ‰JPGæ–‡ä»¶è·¯å¾„"""
    return [
        os.path.join(directory, f)
        for f in os.listdir(directory)
        if f.lower().endswith('.jpg')
    ]


def _build_entity_string(name: str, entity_type: str, description: str) -> str:
    """æ„å»ºå®ä½“å­—ç¬¦ä¸²"""
    return f'("entity"{TUPLE_DELIMITER}"{name}"{TUPLE_DELIMITER}"{entity_type}"{TUPLE_DELIMITER}"{description}"){RECORD_DELIMITER}'


def _build_relationship_string(src: str, tgt: str, description: str, weight: int = 10) -> str:
    """æ„å»ºå…³ç³»å­—ç¬¦ä¸²"""
    return f'("relationship"{TUPLE_DELIMITER}"{src}"{TUPLE_DELIMITER}"{tgt}"{TUPLE_DELIMITER}"{description}"{TUPLE_DELIMITER}{weight}){RECORD_DELIMITER}'


# ============================================================================
# ç‰¹å¾å—å®ä½“æ„å»º
# ============================================================================

async def feature_image_entity_construction(feature_dir: str, llm_func) -> list[str]:
    """ä¸ºç‰¹å¾å—å›¾åƒç”Ÿæˆå®ä½“æè¿°"""
    entities = []
    jpg_files = _get_jpg_files(feature_dir)
    
    if not jpg_files:
        return entities
    
    prompt_user = PROMPTS["feature_image_description_user"]
    prompt_system = PROMPTS["feature_image_description_system"]
    
    for image_path in jpg_files:
        filename = os.path.basename(image_path)
        
        # æ£€æŸ¥å›¾åƒå°ºå¯¸
        with Image.open(image_path) as img:
            width, height = img.size
        
        if width <= MIN_IMAGE_SIZE or height <= MIN_IMAGE_SIZE:
            logger.info(f"ğŸ–¼ï¸ è·³è¿‡å°å›¾åƒ: {filename} ({width}x{height})")
            os.remove(image_path)
            continue
        
        img_base64 = _encode_image_base64(image_path)
        description = await llm_func(
            user_prompt=prompt_user,
            img_base=img_base64,
            system_prompt=prompt_system
        )
        
        entity = _build_entity_string(filename, "img", description)
        entities.append(entity.replace("\n", ""))
    
    return entities


async def feature_image_relationship_construction(
    feature_dir: str, 
    entity_descriptions: str, 
    llm_func
) -> list[str]:
    """æ„å»ºç‰¹å¾å—ä¸å®ä½“ä¹‹é—´çš„å…³ç³»"""
    relationships = []
    jpg_files = _get_jpg_files(feature_dir)
    
    if not jpg_files:
        return relationships
    
    prompt_system = PROMPTS["entity_alignment_system"].format(
        tuple_delimiter=TUPLE_DELIMITER,
        record_delimiter=RECORD_DELIMITER
    )
    
    for image_path in jpg_files:
        filename = os.path.basename(image_path)
        prompt_user = PROMPTS["entity_alignment_user"].format(
            entity_description=entity_descriptions,
            feature_image_name=filename
        )
        
        img_base64 = _encode_image_base64(image_path)
        result = await llm_func(
            user_prompt=prompt_user,
            img_base=img_base64,
            system_prompt=prompt_system
        )
        relationships.append(result)
    
    return relationships


async def extract_entities_from_image(image_path: str, llm_func) -> str:
    """ä»å›¾åƒä¸­æå–å®ä½“"""
    prompt = PROMPTS["image_entity_extraction"].format(
        tuple_delimiter=TUPLE_DELIMITER,
        record_delimiter=RECORD_DELIMITER,
        completion_delimiter=COMPLETION_DELIMITER,
        entity_types=",".join(PROMPTS["DEFAULT_ENTITY_TYPES"]),
    )
    
    img_base64 = _encode_image_base64(image_path)
    return await llm_func(
        user_prompt="Please output the results in the format provided in the example.\nOutput:",
        img_base=img_base64,
        system_prompt=prompt
    )


async def build_original_image_entity(
    image_path: str, 
    feature_entities: list[str], 
    extracted_result: str
) -> list[str]:
    """æ„å»ºåŸå§‹å›¾åƒçš„å®ä½“å’Œå…³ç³»"""
    results = []
    
    image_data = load_json(os.path.join(parameter.WORKING_DIR, "kv_store_image_data.json")) or {}
    
    # æŸ¥æ‰¾å½“å‰å›¾åƒä¿¡æ¯
    filename = None
    description = ""
    for key, info in image_data.items():
        if info.get("image_path") == image_path:
            filename = key
            description = info.get("description", "")
            break
    
    if not filename:
        return results
    
    # æ·»åŠ åŸå§‹å›¾åƒå®ä½“
    entity = _build_entity_string(filename, "ori_img", description)
    results.append(entity.replace("\n", ""))
    
    # æ·»åŠ ç‰¹å¾å—ä¸åŸå§‹å›¾åƒçš„å…³ç³»
    pattern = r'\"([^\"]+?\.jpg)\"'
    for feature_entity in feature_entities:
        matches = re.findall(pattern, feature_entity)
        if matches:
            rel = _build_relationship_string(
                matches[0], filename, f"{matches[0]}æ˜¯{filename}çš„å›¾åƒç‰¹å¾å—ã€‚"
            )
            results.append(rel)
    
    # æ·»åŠ æå–å®ä½“ä¸åŸå§‹å›¾åƒçš„å…³ç³»
    entity_pattern = r'\"entity\"\<\|\>\"([^\"]+?)\"'
    for entity_name in re.findall(entity_pattern, extracted_result):
        rel = _build_relationship_string(
            entity_name, filename, f"{entity_name}æ˜¯ä»{filename}ä¸­æå–çš„å®ä½“ã€‚"
        )
        results.append(rel)
    
    return results


def format_entities_result(result: str) -> str:
    """æ ¼å¼åŒ–å®ä½“æå–ç»“æœ"""
    pattern = r'\("entity"<\|>"([^"]+)"<\|>"[^"]*"<\|>"([^"]+)"\)'
    entities = re.findall(pattern, result)
    return "\n".join([f'"{e}"-"{d}"' for e, d in entities])


# ============================================================================
# ä¸»æå–å‡½æ•°
# ============================================================================

async def extract_entities(
    cache_storage: BaseKVStorage,
    image_path: str,
    feature_dir: str,
    knwoledge_graph_inst: BaseGraphStorage,
) -> Union[BaseGraphStorage, None]:
    """ä»å›¾åƒæå–å®ä½“å¹¶æ„å»ºçŸ¥è¯†å›¾è°±"""
    
    llm_func = limit_async_func_call(16)(
        partial(multimodel_if_cache, hashing_kv=cache_storage)
    )
    
    # æå–å„ç±»å®ä½“å’Œå…³ç³»
    feature_entities = await feature_image_entity_construction(feature_dir, llm_func)
    image_entities = await extract_entities_from_image(image_path, llm_func)
    formatted_entities = format_entities_result(image_entities)
    relationships = await feature_image_relationship_construction(feature_dir, formatted_entities, llm_func)
    original_entities = await build_original_image_entity(image_path, feature_entities, image_entities)
    
    # åˆå¹¶æ‰€æœ‰ç»“æœ
    all_results = feature_entities + relationships + original_entities
    final_result = "\n" + "\n".join(all_results) + image_entities.strip()
    
    # è§£æè®°å½•
    records = split_string_by_multi_markers(
        final_result, [RECORD_DELIMITER, COMPLETION_DELIMITER]
    )
    
    maybe_nodes = defaultdict(list)
    maybe_edges = defaultdict(list)
    
    for record in records:
        match = re.search(r"\((.*)\)", record)
        if not match:
            continue
        
        attrs = split_string_by_multi_markers(match.group(1), [TUPLE_DELIMITER])
        
        entity = await _handle_single_entity_extraction(attrs, image_path)
        if entity:
            maybe_nodes[entity["entity_name"]].append(entity)
            continue
        
        relation = await _handle_single_relationship_extraction(attrs, image_path)
        if relation:
            maybe_edges[(relation["src_id"], relation["tgt_id"])].append(relation)
    
    # åˆå¹¶èŠ‚ç‚¹ï¼ˆæŒ‰åç§°å»é‡ï¼‰
    merged_nodes = {}
    for name, data_list in maybe_nodes.items():
        merged_nodes[name] = data_list
    
    # åˆå¹¶è¾¹ï¼ˆæ— å‘å›¾æ’åºï¼‰
    merged_edges = {}
    for key, data_list in maybe_edges.items():
        sorted_key = tuple(sorted(key))
        merged_edges.setdefault(sorted_key, []).extend(data_list)
    
    # æ›´æ–°çŸ¥è¯†å›¾è°±
    all_entities = await asyncio.gather(*[
        _merge_nodes_then_upsert(k, v, knwoledge_graph_inst)
        for k, v in merged_nodes.items()
    ])
    
    await asyncio.gather(*[
        _merge_edges_then_upsert(k[0], k[1], v, knwoledge_graph_inst)
        for k, v in merged_edges.items()
    ])
    
    if not all_entities:
        logger.warning("æœªæå–åˆ°ä»»ä½•å®ä½“")
        return None
    
    return knwoledge_graph_inst


# ============================================================================
# æå–å™¨ç±»
# ============================================================================

@dataclass
class ImageEntityExtractor:
    """å›¾åƒå®ä½“æå–å™¨"""
    extraction_func: callable = extract_entities
    kv_storage_cls: Type[BaseKVStorage] = JsonKVStorage
    graph_storage_cls: Type[BaseGraphStorage] = NetworkXStorage
    
    def __post_init__(self):
        self.llm_cache = self.kv_storage_cls(
            namespace="multimodel_llm_response_cache",
            storage_dir=parameter.CACHE_PATH
        )
        self.graph = self.graph_storage_cls(namespace="image_entity_relation")
    
    async def extract(self, image_path: str):
        """æå–å•å¼ å›¾åƒçš„å®ä½“"""
        try:
            feature_dir = await extract_feature_chunks(image_path)
            logger.info("ğŸ” æ­£åœ¨æå–å®ä½“...")
            
            result = await self.extraction_func(
                self.llm_cache,
                image_path,
                feature_dir,
                knwoledge_graph_inst=self.graph,
            )
            
            if result is None:
                logger.warning("æœªæ‰¾åˆ°å®ä½“")
            else:
                self.graph = result
        finally:
            await self._save()
    
    async def _save(self):
        """ä¿å­˜å­˜å‚¨"""
        tasks = [
            cast(StorageNameSpace, s).index_done_callback()
            for s in [self.llm_cache, self.graph] if s
        ]
        await asyncio.gather(*tasks)

# ============================================================================
# å…¥å£å‡½æ•°
# ============================================================================

async def img2graph(images_dir: str):
    """
    å¤„ç†ç›®å½•ä¸‹æ‰€æœ‰å›¾åƒï¼Œæ„å»ºçŸ¥è¯†å›¾è°±ã€‚
    
    Args:
        images_dir: åŒ…å«JPGå›¾åƒçš„ç›®å½•è·¯å¾„
    """
    jpg_files = _get_jpg_files(images_dir)
    
    if not jpg_files:
        return
    
    for image_path in tqdm(jpg_files, desc="ğŸ–¼ï¸ å›¾åƒå®ä½“æå–", unit="å¼ "):
        image_name = Path(image_path).stem
        target_graph_path = os.path.join(
            parameter.WORKING_DIR, "images", image_name,
            f"graph_{image_name}_entity_relation.graphml"
        )
        
        if os.path.exists(target_graph_path):
            # logger.info(f"âœ“ è·³è¿‡å·²å¤„ç†å›¾åƒ: {image_name}")
            continue

        extractor = ImageEntityExtractor()
        await extractor.extract(image_path)
        
        # ç§»åŠ¨ç”Ÿæˆçš„å›¾è°±æ–‡ä»¶
        src = os.path.join(parameter.WORKING_DIR, "graph_image_entity_relation.graphml")
        dst = target_graph_path
        
        if os.path.exists(src):
            shutil.move(src, dst)